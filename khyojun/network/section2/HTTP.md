# HTTP


이번 챕터에서는 물론 다른 여러 가지 정보에 대해서 나오긴 하지만 HTTP 1.0, 1.x, 2, 3으로 진화해 갈수록 어떤 장점들이 있는지에 대한 비교를 해가며 시작하면 좋을 거 같다.

HTTP는 기본적으로 애플리케이션 계층으로 웹 서비스 통신에 사용이 된다. 

## HTTP/1.0

HTTP/1.0은 기본적으로 한 연결당 하나의 요청을 처리하도록 설계가 되어졌다. 이는 *RTT라는 것의 증가를 불러오게 되었다.

### RTT
> RTT(Round Trip Time):  패킷이 목적지에 도달하고 나서 해당 패킷에 대한 응답이 출발지로 다시 돌아오기까지의 시간. `패킷 왕복 시간` 이라고도 부른다.

여기서 한 연결당 하나의 요청을 처리한다고 하였는데 이게 진짜 말 그대로 한 요청에 여러개 파일을 하나로 묶어서 보내는 것이 아니라, 진짜 하나만 보내는 것이었다. 이러면 요청을 할 때마다 TCP 3 웨이 핸드쉐이크 과정을 진행하게 되는데 너무 비효율적이다. 

이렇게 되면 당연히 이 RTT도 늘어날 수 밖에 없다. 

### RTT vs Latency

갑자기 떠오른 레이턴시인데 두 가지는 결국 똑같은거 아닌가? 하는 생각이 떠올랐다. 

결론은 이러했다.
> - Latency는 전송의 첫 번째 비트가 A에서 B로 이동하는 데 걸리는 시간입니다.
> - RTT는 A에서 B로 전송하고 B에서 A로 응답하는 데 걸리는 시간입니다.

그래서 다른 분들에게 수소문할 결과 개념이 latency > RTT 이런식으로 나오는데 범위 순이라고 보면 될 거 같다.

- latency는 말 그대로 장치 끼리 의 지연시간이다. 즉 a에서 b까지 가는 통신 중 라우터 끼리의 요청 왕복시간 느낌으로 봐도 된다. 
- RTT는 단말 간의 왕복 시간을 말하는 것이기에  RTT의 시간을 더하는 과정 중 그 안에는 결국 latency들을 다 더하는 값이 될 수 있다는 의미였다.

그래서 약간 범위의 차이인 느낌이 더 강해서 다른 설명들이 애매했던 경향이 있던 거 같다.


### 그래서 왜 RTT 얘기가 나왔냐면

HTTP/1.0에서는 결국 TCP 3 way handshake라는 말이 많이 나오는데 RTT가 이것 때문에 많이 시간이 걸리기 때문이다. 그리고 심지어 그 시대에는 이런 시간들이 현재와는 다르게
엄청 오래 걸렸다고 한다. 그래서 반드시 줄여야만 했다. 그래서 어떻게 해결방안들이 필요했는데 하나씩 보자.

### 이미지 스플리팅

> 이미지 스플리팅: 많은 이미지를 다운 받으면 과부화가 걸리기 때문에 많은 이미지를 합쳐서 하나의 이미지를 다운 받은 후 background-image의 position을 이용하여 이미지를 표기하는 방식

이미지를 짬뽕 시킨 후 나중에 설정을 통해서 위치를 변동시켜 표시하는 방식이었다고 한다.

### 코드 압축

> 코드 압축 : 코드를 압축해서 개행 문자, 빈칸을 없애서 코드의 크기를 최소하시키는 방법.

이런 느낌이다.

```java

public static void main(String[]args){
    
    System.out.println("hello world");
    }

```


```java
public static void main(String[]args){System.out.println("hello world");}
```

위 코드를 아래처럼 불필요한 부분들은 다 없애는 식으로 코드 용량을 줄여나갔다고 한다.

### 이미지 Base64 인코딩

> 이미지 Base64: 이미지 파일을 64진법으로 이루어진 문자열로 인코딩하는 방법이다. 이 방법을 이용하면 이미지에 대해 서버에 HTTP 요청을 할 필요가 없다고 한다.
> 그렇지만 Base64 문자열로 변환 시 37% 정도 크기가 더 커지는 단점이 생겨버린다.

### 어떻게 서버에 요청을 또 안 보내지?
이게 왜 그렇게 되는지 보게 되었는데 여러 html 태그에 src의 속성으로 url을 놓게 되면 추가적인 http 요청을 한다고 한다. 그러면 위 같은 과정을 또 실행해야되니 이렇게 base64로 인코딩해서 html출력에 직접 박아버리니
서버에 요청을 할 필요가 없다는 것이었다.


## HTTP/1.1

그래서 위와 같은 단점들이 이전 버전에는 많아 발전을 해서 1.1버전이 나왔다 어떤 점들이 더 생겼는지 알아보자.

### Keep-alive

기존의 HTTP에서는 한 연결 당 한 요청을 처리한다고 했는데 이게 딱 봐도 너무 비효율적이다. 그래서 keep-alive라는 속성을 사용해 한 번 연결 하였을때 여러 개의 파일을 송수신할 수 있도록 하였다.
> 번외이긴 하지만 1.0에서도 있긴 했는데 표준화가 1.1버전부터 되었다고 한다.

그치만 이 방식에도 문제는 있었는데 여러개의 리소스들을 보내다보니 요청할 리소스 개수에 비례해서 대기 시간이 길어진다는 단점들이 생겼다.

### HOL BLOCKING
> HOL(Head Of Line) Blocking : 네트워크에서 같은 큐에 있는 패킷이 그 첫 번째 패킷에 의해 지연될 때 발생하는 성능 저하 현상을 말한다.

이 말을 보게 되면 이해가 잘 되지 않아 도로에서의 예시를 들어보면 앞의 나는 우회전을 할려고 하는데 앞의 차가 직진을 하는 차다. 그런데 앞에서 신호가 걸려서 직진을 앞의 차가 하지 못해 나는 계속 대기를 해야되는 상태가 HOL Blocking과 같은 상태이다.

책에서는 이에 대한 예제로 3개의 리소스들을 다운받을 때 맨 앞에 있는 파일을 다운로드 받는 과정에서 너무 시간이 걸려 뒤에 있는 파일까지 늦게 받아지는 현상으로 예시를 들어주고 있다.


### 무거운 헤더 구조

HTTP/1.1에서는 헤더에 쿠키 등 많은 메타데이터가 들어 있고 압축이 되지 않아 많이 무거웠는데 이런 요청들을 많이 보내야 되서 비효율적이었다고 한다.


## HTTP/2

애초에 숫자에서부터 변경된 것부터 많은 변화가 일어난 것처럼 보이는데 위에 있었던 HTTP/1.x 버전들의 단점들을 보완시켜 지연 시간을 줄이고 응답 시간을 더 빠르게
할 수 있도록 하였다고 한다. 그 안에 `멀티플렉싱`, `헤더 압축`, `서버 푸시`, `요청의 우선순위` 처리를 지원하는 프로토콜이다.

### 멀티플렉싱

> 멀티플렉싱 : 여러 개의 스트림을 사용하여 송수신을 한다는 것. 이를 통해 특정 스트림의 패킷이 손실되었다고 해도 해당 스트림에만 영향을 미치고 나머지 스트림은 멀쩡하게 동작할 수 있다.

이 말이 뭐냐면 HTTP/1.x 버전들과 비교해서 볼 때 한 연결에 하나의 요청을 처리하는 것처럼 진행을 할 때 2버전에서는 단일 연결을 사용해 병렬로 여러 요청을 받을 수 있고 응답을 줄 수 있다.

이래서 위에 말했던 `HOL Blocking`의 문제를 해결할 수 있었다.

### 헤더 압축

앞에서 말했던 대로 HTTP/1.x 버전들에서는 헤더들이 너무 크다는 문제가 있었다. 그래서 헤더 압축을 진행하게 되었는데 이때 허프만 코딩 압축 알고리즘을 사용하는 HPACK 압축 형식을 가졌다고 한다.

> 허프만 코딩 : 문자열 안의 문자의 빈도수를 세어 빈도가 높은 정보는 적은 비트 수를 사용하여 표현, 낮은 정보는 비트 수를 많이 사용하여 표현해 전체 데이터 표현에 필요한 비트양을 줄이는 원리.
> 참고 : https://playground10.tistory.com/98



### 서버 푸시

이전 버전에서는 클라이언트가 서버에 요청을 해야 파일을 다운로드 받을 수 있었는데 이제는 더 이상 그럴 필요가 없다고 한다. 2 버전에서는 클라이언트 요청 없이 서버가 바로 리소스를 푸시할 수 있다고 한다.

html안에 css나 js 파일이 포함이 되어있는 경우가 많은데 그럴 때 html을 읽으면서 그 안에 들어 있던 css 파일을 서버에서 푸시하여 클라이언트에게 먼저 줄 수 있는 그런 방식이다.



### HTTPS

HTTP/2는 HTTPS 위에서 동작을 한다고 한다. 뒤에 붙은 S는 Secure이다. HTTPS는 애플리케이션 계층과 전송 계층 사이에 신뢰 계층인 `SSL/TLS` 계층을 넣은 신뢰할 수 있는 HTTP 요청이라고 한다. 이를 통해 
통신을 `암호화` 한다고 한다. 

### HTTP는 보안에 왜 취약했을까?

다음의 2가지 이유라고 한다.
> - 암호화 안된 방식으로 데이터를 주고 받음 : 데이터를 중간에 가로챌 수 있음.
> - 통신하는 상대방의 신원을 확인하지 않음 : 상대방이 누군지 확인하지 않고 요청/응답을 보냄. 중간에 상대방인척하고 데이터를 가로챌 수 있음.

그래서 암호화를 전혀 하지 않아 중요한 신용카드 정보나 결제 정보같은 것은 그냥 뚫려버릴 수가 있다. 그래서 꼭 HTTPS를 활용해야지 보안을 지킬 수 있는 것이었다.

### SSL/TLS

SSL은 SSL 1.0부터 시작해서 2.0,3.0, TLS 1.0, 1.3 버전이 올라가며 마지막에 TLS로 명칭이 변경되었으나, 이를 합쳐서 SSL/TLS라고 많이 부른다. 

> - SSL(SECURE SOCKETS LAYER) :SSL은 웹사이트와 브라우저 사이(또는 두 서버 사이)에 전송되는 데이터를 암호화하여 인터넷 연결을 보호하기 위한 표준 기술입니다.
> - TLS(Transport Layer Security) : TLS은 SSL의 향상된, 더욱 안전한 버전입니다.

SSL/TLS는 기본적으로 전송 계층에서 보안을 제공하는 프로토콜이다. 제 3자가 메시지를 도청하거나 변조하지 못하도록 방지하는 기능을 가진다. 

예를 들면, 클라이언트와 서버와의 통신 중간에 해커가 정보를 사용자인 척 정보를 중간에서 가로채는 `인터셉터`를 방지할 수가 있는 것이 SSL/TLS기능이다.

SSL/TLS은 `보안 세션`을 기반으로 데이터를 암호화하며 보안 세션이 만들어질 때 `인증 메커니즘`, `키 교환 암호화 알고리즘`, `해싱 알고리즘`이 사용된다.

---
#### 보안 세션

> 보안 세션: 보안이 시작되고 끝나는 동안 유지되는 *세션, SSL/TLS는 핸드셰이크를 통해 보안 세션을 생성하고 이를 기반으로 상태 정보를 공유한다.
> 세션 : 운영체제가 어떠한 사용자로부터 자신의 자산 이용을 허락하는 일정한 기간을 뜻한다. 사용자는 일정 시간동안 응용 프로그램, 자원 등을 사용할 수 있다.

---

클라이언트랑 서버가 키를 공유하고 이를 기반으로 `인증`, `인증 확인` 등의 작업이 일어나는데 이때 단 한번의 1-RTT가 생긴 후 데이터를 송수신한다. 

여기서 1-RTT 즉 한번만 일어났다고 보면 된다.

그래서 클라이언트에서 사이퍼 슈트?를 서버에 전달하면 서버는 받은 사이퍼 슈트의 암호화 알고리즘 리스트를 제공할 수 있는지 확인한다.

그 이후 서버에서 제공할 수 있다면 클라이언트로 인증서를 보내는 인증 메커니즘이 시작되고 이후 해싱 알고리즘 등으로 암호화된 데이터의 송수신이 시작이 된다. 

### 사이퍼 슈트?

> 사이퍼 슈트 : 프로토콜, AEAD 사이퍼 모드, 해싱 알고리즘이 나열된 규약을 말하고, 다섯 개가 있다고 한다.
> - TLS_AES_128_GCM_SHA256
> - TLS_AES_256_GCM_SHA384
> - TLS_CHACHA20_POLY1305_SHA256
> - TLS_AES_128_CCM_SHA256
> - TLS_AES_128_CCM_8_SHA256

이렇게만 보면 이게 무슨 말이야? 도대체 이럴 수 있는데 차근차근 보자. 일단 보기 전에 사이퍼 슈트! 라고 했으니까 아이언맨 슈트처럼 뭔가 감싸서 있는 것일거다. 그정도로만 알고 있자.

그래서 간략히 이걸 뜯어보면

> TLS_AES_128_GCM_SHA256 : 세 가지 규약이 있다. TLS : 프로토콜, AES_128_GCM : AEAD 사이퍼 모드, SHA256: 해싱 알고리즘 이렇게 뜻을 한다.


### AEAD 사이퍼 모드

>AEAD(Authenticated Encryption with Associated Data) 는 데이터 암호화 알고리즘인데 AES-128_GCM 등등이 있다.

AES_128_GCM을 뜯어보면 128비트의 키를 사용하는 표준 블록 암호화 기술과 병렬 계산에 용이한 암호화 알고리즘 GCM이 결합된 알고리즘이라고 한다.

여기서 그러면 인증 메커니즘이 어떻게 돌아가는지 또 볼 필요가 있다.

### 인증이 되는 메커니즘

인증 메커니즘이 CA(Certificate Authorities)에서 발급한 인증서를 기반으로 이루어지는데 한 마디로 인증서가 있어야지 신뢰할 수 있는 서버다. 이런 느낌이다. 

그래서 그 인증서 안에는 서비스 정보, 공개키, 지문, 디지털 서명으로 이루어져있다. 그래서 이 CA는 아무나 할 수 있는 것이 아니라 공인된 곳에서만 참여할 수 있다.

> 참고 : https://www.digicert.com/kr/what-is-ssl-tls-and-https


### CA가 나오게 되는 과정

CA 인증서를 발급받으려면 자신의 사이트 정보, 공개키를 CA에 제출해야 한다. CA의 비밀 키 등을 기반으로 CA 인증서를 발급한다.

### 암호화 알고리즘

키 교환 암호화 알고리즘으로는 대수곡선 기반의 ECDHE, 모듈식 기반의 DHE를 사용을 하는데 둘 다 디피-헬만(Diffie-Hellman) 방식을 근간으로 만들어진다고 한다. 

디피-헬만 키 교환 암호화 알고리즘은 암호키를 교환하는 하나의 방법이다. 

간단 요약
> 1. 공개 값 공유한다.
> 2. 각자의 비밀 값과 혼합한 후 혼합 값을 공유
> 3. 이후 공통의 암호키가 생성

공개키를 보내고 공개키와 개인키를 결합하여 PSK(사전 합의된 비밀키)가 생성되면, 악의적인 공격자가 개인키 또는 공개키를 가지고도 PSK가 없기 때문에 아무것도 할 수 없다고 한다.

### 해싱 알고리즘

> 해싱 알고리즘: 데이터를 추정하기 힘든 더 작고, 섞여 있는 조각으로 만드는 알고리즘이다.

SSL/TLS는 해싱 알고리즘으로 SHA-256 알고리즘, SHA-384 알고리즘을 쓰며, 그중 많이 쓰는 SHA-256 알고리즘을 보자.


### SHA-256 알고리즘

해시 함수의 결괏값이 256비트인 알고리즘이다. 비트 코인을 비롯한 많은 블록체인 시스템에서도 쓴다.

그래서 막 보면 간단한 문장 하나도 이런 해싱 알고리즘을 적용하면 정말 못 알아보게 만들어준다. 

> - 해시 : 다양한 길이를 가진 데이터를 고정된 길이를 가진 데이터로 매핑한 값
> - 해싱 : 임의의 데이터를 해시로 바꿔주는 일이며 해시 함수가 이를 담당
> - 해시 함수 : 임의의 데이터를 입력으로 받아 일정한 길이의 데이터로 바꿔주는 함수

### SEO에도 도움이 되는 HTTPS

> SEO(Search Engine Optimization)은 검색엔진 최적화를 뜻하는데 사용자들이 구글, 네이버 같은 검색엔진으로 웹 사이트를 검색했을 때 그 결과를 페이지 상단에 노출시켜주는 방법을 의미한다.

서비스를 운영하는 입장에서 SEO 관리는 필수이다. 그러기 위한 방법으로는 캐노니컬 설정, 메타 설정, 페이지 속도 개선, 사이트맵 관리 등이 있다.

### 캐노니컬 설정

link 태그의 속성 중 rel이라는 설정에 canonical이라는 설정을 넣어주는 것인데 이것을 왜 하냐면? 구글에서는 실제로 여러개의 url이 있을때 동일한 url이지만 다르게 처리하여 중복 url로 패널티를 주기 때문에
페이지 상단에 노출시켜주지를 않는다. 그러한 것을 방지하기 위하여서 설정을 하는 것이다.

### 메타 설정

html의 메타 설정을 잘 해놔야지 상단에 올라간다고 한다.

### 페이지 속도 개선

사이트의 속도가 빨라야지 사용자들이 접속을 많이 해서 상단으로 올라가게 된다.

### 사이트맵 관리

사이트맵을 정기적으로 관리하여서 좋은 사이트가 될 수 있도록 관리해줘야 한다.

그래서 뭐 그런건 다 알겠는데 그래서 HTTPS랑 무슨 연관이냐? 라고 하면
> 구글에서는 SSL 인증서를 강조하기 때문에 사이트 내 모든 요소가 동일하다면 HTTPS 서비스를 하는 사이트와 그렇지 않은 사이트의 우선 순위를 둘 때 HTTPS를 사용하는 사이트의 우선 순위가 높을 거라고 말했기 때문이다.


### HTTPS를 구축하는 방법

크게 3가지라고 한다.
1. 직접 CA에서 구매한 인증키를 기반으로 HTTPS 서비스를 구축
2. 서버 앞단의 HTTPS를 제공하는 로드 밸런서를 두는 방법
3. 서버 앞단에 HTTPS를 제공하는 CDN을 줘서 구축



### 인증키 기반 HTTPS 서비스 구축

말 그대로 인증키를 통하여서 서버에 등록하여서 HTTPS로 구축하는 방법이다.

### 서버 앞단의 HTTPS를 제공하는 로드 밸런서를 두기

이것에 대해 말하기 이전에 로드 밸런서라는 역할을 제대로 알고 가야겠다.

> 로드 밸런싱 : 로드 밸런서는 사용자와 서버 그룹 사이에 위치하며 보이지 않는 촉진자 역할을 하여 모든 리소스 서버가 동일하게 사용되도록 하는 디바이스입니다.

이런 역할을 하는데 여러 개의 서버가 있는데 하나에서만 포화되게 하지 않도록 관리해주는 관리자의 역할로 보면 좋을 거 같다.

이를 통해서 서버 앞단의 HTTPS를 제공하는 로드 밸런서를 통하여서 뒷단에 있는 서버들에게 HTTPS를 뿌려주는 방식처럼 보면 되겠다.;


### 서버 앞단에 HTTPS를 제공하는 CDN을 줘서 구축

위 로드 밸런서를 통한 구축과 비슷하게 CDN 서버들을 통하여서 거쳐갈때 HTTPS를 설정해주게 되면 설정이 되어간다는 것으로 알 수 있다.


> 암호화, 복호화 HTTPS 관련 참고 : https://www.bsidesoft.com/3340


## HTTP/3

이전 방식들과는 다르게 이제 TCP 위에서 돌아가는 것이 아닌 QUIC라는 계층 위에서 돌아가 TCP가 아닌 UDP 기반으로 HTTP/3를 돌아가게 한다.

이전 HTTP/2의 장점인 멀티플렉싱을 가지고 있어서 초기 연결 설정 시 지연 시간 감소라는 장점이 있다.

### 초기 연결 설정 시 지연 시간 감소

우선 TCP 기반이 아니라 hand shaking하지 않는다. 그러면 QUIC는 첫 연결을 설정할 때 1-RTT만 소요하는데 그러면 어떻게 패킷이 잘 도착하는지 보장을 할까?

### QUIC란?

>QUIC (Quick UDP Internet Connections)
전송 계층 프로토콜 (2013년에 구글에서 공개)

### 순방향 오류 수정 메커니즘(FEC, Forward Error Correction) 
> 전송한 패킷이 손실되었다면 수신 측에서 에러를 검출하고 수정하는 방식이며 열악한 네트워크 환경에서도 낮은 패킷 손실률을 자랑

### TCP가 아닌 UDP를 선택한 이유?
- TCP 헤더는 신뢰성을 확보하지만 지연을 줄이기 힘든 구조
- UDP는 데이터 전송에 집중한 설계로 별도의 기능이 없음

### QUIC의 장점
> - 전송 속도 향상 
> - 첫 연결 설정에서 필요한 정보와 함께 데이터를 전송
>  - 연결 성공 시 설정을 캐싱하여 다음 연결 때 바로 성립 가능
> - Connection UUID라는 고유한 식별자로 서버와 연결
>   - 커넥션 수립 필요가 없음
> - TLS (전송 계층 보안, Transport Layer Security) 기본 적용
> - IP Spoofing / Replay Attack을 방지하여 보안성을 향상


그래서 현재는 구글에서는 HTTP/3를 적극적으로 사용하고 있다고 하고 네이버에서는 2,3를 섞어서 사용한다고 한다.
